{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言模型，由Google在2018年提出。BERT通过大规模的无监督预训练来学习通用的语言表示，然后在各种NLP任务上进行微调，取得了显著的性能提升。\n",
    "\n",
    "BERT的原理如下：\n",
    "\n",
    "1. **Transformer架构**：BERT使用Transformer编码器作为基础架构，包括多层的自注意力机制和前馈神经网络。这种架构能够更好地捕捉输入序列的全局依赖关系。\n",
    "\n",
    "2. **双向性**：BERT通过两种预训练任务来训练模型，包括Masked Language Model（MLM）和Next Sentence Prediction（NSP）。MLM任务要求模型预测句子中被掩盖的词语，从而使模型能够理解句子的上下文关系；NSP任务要求模型判断两个句子是否是原文中相邻的句子，从而使模型能够理解句子间的逻辑关系。\n",
    "\n",
    "3. **预训练和微调**：BERT首先在大规模文本语料上进行无监督预训练，学习通用的语言表示。然后，在特定的下游任务上进行微调，通过少量标记数据即可取得较好的效果。\n",
    "\n",
    "BERT解决了传统语言模型的一些问题，包括：\n",
    "\n",
    "- **上下文理解**：传统的语言模型（如Word2Vec和GloVe）无法考虑句子中词语的上下文信息，而BERT通过双向性和Transformer架构能够更好地理解句子中的语境，从而提高了语言表示的质量。\n",
    "\n",
    "- **迁移学习**：传统的语言模型通常需要针对特定任务重新训练，而BERT的预训练-微调框架使得模型可以更轻松地应用于各种NLP任务，极大地提高了模型的可迁移性和通用性。\n",
    "\n",
    "BERT有多个版本，其中最知名的是BERT-base和BERT-large。它们的参数规模分别如下：\n",
    "\n",
    "- BERT-base：包含110M个参数，包括12个Transformer编码器层，每层有12个注意力头，隐藏层大小为768。\n",
    "- BERT-large：包含340M个参数，包括24个Transformer编码器层，每层有16个注意力头，隐藏层大小为1024。\n",
    "\n",
    "除此之外，还有一些针对特定任务或语言的变体，如多语言BERT（BERT-multilingual）等。BERT的提出极大地推动了自然语言处理领域的发展，并在许多任务上取得了state-of-the-art的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert模型文件下载地址 https://huggingface.co/bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\download\\sd\\sd-webui-aki-v4.5\\python\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2769, 4263, 1266, 776, 1921, 2128, 7305, 102]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "input_text = \"我爱北京天安门\"\n",
    "# 通过tokenizer把文本变成 token_id\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 21128])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([input_ids])\n",
    "# 获得BERT模型最后一个隐层结果\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       label                                             review\n",
      "0     label                                             review\n",
      "1         0                      商业秘密的秘密性那是维系其商业价值和垄断地位的前提条件之一\n",
      "2         1  南口阿玛施新春第一批限量春装到店啦         春暖花开淑女裙、冰蓝色公主衫  ...\n",
      "3         0                                   带给我们大常州一场壮观的视觉盛宴\n",
      "4         0                                      有原因不明的泌尿系统结石等\n",
      "...     ...                                                ...\n",
      "1238      0                                    关于两英女孩嫁海门惨遭家暴之后\n",
      "1239      0          美国Amazon购买$50礼品卡部分用户送$10promotionalcredit\n",
      "1240      0                                   一年中这是最好的调理疾病的好时候\n",
      "1241      0                              我镇强力推进“3+2+2”专项打击整治行动\n",
      "1242      0                                       ~热推~全球最好的祛疤膏\n",
      "\n",
      "[1243 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#1、加载数据\n",
    "train_df = pd.read_csv('data.csv', encoding='utf-8', header=None, names=['label','review'])\n",
    "print(train_df.head)\n",
    "\n",
    "sentences = list(train_df['review'][1:])\n",
    "label =train_df['label'][1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1120, '1': 122}\n"
     ]
    }
   ],
   "source": [
    "c = Counter(label)\n",
    "print (dict(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 token encodding\n",
    "\n",
    "max_length=32\n",
    "sentences_tokened=tokenizer(sentences,padding=True,truncation=True,max_length=max_length, return_tensors='pt')\n",
    "label=torch.tensor(label.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993, 249]\n"
     ]
    }
   ],
   "source": [
    "#3 encoding data\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "\n",
    "class DataToDataset(Dataset):\n",
    "    def __init__(self,encoding,labels):\n",
    "        self.encoding=encoding\n",
    "        self.labels=labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.encoding['input_ids'][index],self.encoding['attention_mask'][index],self.labels[index]\n",
    "\n",
    "#封装数据\n",
    "datasets=DataToDataset(sentences_tokened,label)\n",
    "train_size=int(len(datasets)*0.8)\n",
    "test_size=len(datasets)-train_size\n",
    "print([train_size,test_size])\n",
    "train_dataset,val_dataset=random_split(dataset=datasets,lengths=[train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "#这里的num_workers要大于0\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "val_loader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\download\\sd\\sd-webui-aki-v4.5\\python\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTextClassficationModel(\n",
       "  (bert): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4、create model\n",
    "class BertTextClassficationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertTextClassficationModel,self).__init__()\n",
    "        self.bert=BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=2)\n",
    "        \n",
    "    def forward(self,ids,mask):\n",
    "        out = self.bert(input_ids=ids,attention_mask=mask)\n",
    "        return out[0]\n",
    "\n",
    "\n",
    "mymodel=BertTextClassficationModel()\n",
    "\n",
    "\n",
    "#获取gpu和cpu的设备信息\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(\"Let's use \",torch.cuda.device_count(),\"GPUs!\")\n",
    "    mymodel=nn.DataParallel(mymodel)\n",
    "mymodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.bert.embeddings.word_embeddings.weight : torch.Size([21128, 768])\n",
      "bert.bert.embeddings.position_embeddings.weight : torch.Size([512, 768])\n",
      "bert.bert.embeddings.token_type_embeddings.weight : torch.Size([2, 768])\n",
      "bert.bert.embeddings.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.embeddings.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.0.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.0.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.0.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.1.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.1.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.1.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.2.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.2.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.2.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.3.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.3.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.3.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.4.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.4.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.4.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.5.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.5.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.5.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.6.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.6.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.6.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.7.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.7.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.7.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.8.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.8.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.8.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.9.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.9.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.9.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.10.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.10.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.10.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.11.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.11.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.11.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.pooler.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.pooler.dense.bias : torch.Size([768])\n",
      "bert.classifier.weight : torch.Size([2, 768])\n",
      "bert.classifier.bias : torch.Size([2])\n",
      "模型需要训练参数为： 102269186\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for name, parameters in mymodel.named_parameters():\n",
    "    if not parameters.requires_grad: continue\n",
    "    print(name, ':', parameters.size())\n",
    "    total_params += parameters.numel()\n",
    "print(\"模型需要训练参数为：\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1/3 epochs Batch 10 Loss:0.336873, Acc:0.862500\n",
      "train 1/3 epochs Batch 20 Loss:0.305873, Acc:0.884375\n",
      "train 1/3 epochs Batch 30 Loss:0.224474, Acc:0.916667\n",
      "train 1/3 epochs Batch 40 Loss:0.229717, Acc:0.915625\n",
      "train 1/3 epochs Batch 50 Loss:0.210660, Acc:0.927500\n",
      "train 1/3 epochs Batch 60 Loss:0.184388, Acc:0.936458\n",
      "train 1/3 epochs Loss:0.181004, Acc:0.938492\n",
      "train 2/3 epochs Batch 10 Loss:0.006369, Acc:1.000000\n",
      "train 2/3 epochs Batch 20 Loss:0.051118, Acc:0.987500\n",
      "train 2/3 epochs Batch 30 Loss:0.054556, Acc:0.989583\n",
      "train 2/3 epochs Batch 40 Loss:0.042382, Acc:0.992188\n",
      "train 2/3 epochs Batch 50 Loss:0.035039, Acc:0.993750\n",
      "train 2/3 epochs Batch 60 Loss:0.042860, Acc:0.992708\n",
      "train 2/3 epochs Loss:0.041098, Acc:0.993056\n",
      "train 3/3 epochs Batch 10 Loss:0.007164, Acc:1.000000\n",
      "train 3/3 epochs Batch 20 Loss:0.005960, Acc:1.000000\n",
      "train 3/3 epochs Batch 30 Loss:0.024603, Acc:0.995833\n",
      "train 3/3 epochs Batch 40 Loss:0.053970, Acc:0.990625\n",
      "train 3/3 epochs Batch 50 Loss:0.101436, Acc:0.976250\n",
      "train 3/3 epochs Batch 60 Loss:0.135478, Acc:0.965625\n",
      "train 3/3 epochs Loss:0.138734, Acc:0.965278\n"
     ]
    }
   ],
   "source": [
    "#5、train model\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(mymodel.parameters(),lr=0.0001)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def flat_accuracy(preds,labels):\n",
    "    pred_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return accuracy_score(labels_flat,pred_flat)\n",
    "\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc=0.0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        input_ids,attention_mask,labels=[elem.to(device) for elem in data]\n",
    "        #优化器置零\n",
    "        optimizer.zero_grad()\n",
    "        #得到模型的结果\n",
    "        out=mymodel(input_ids.long(),attention_mask)\n",
    "        #计算误差\n",
    "        loss=loss_func(out,labels)\n",
    "        train_loss += loss.item()\n",
    "        #误差反向传播\n",
    "        loss.backward()\n",
    "        #更新模型参数\n",
    "        optimizer.step()\n",
    "        #计算acc \n",
    "        #out=out.detach().numpy()\n",
    "        out=out.detach().cpu().numpy()\n",
    "        #labels=labels.detach().numpy()\n",
    "        labels=labels.detach().cpu().numpy()\n",
    "        train_acc+=flat_accuracy(out,labels)\n",
    "        if (i + 1) % 10 == 0:\n",
    "                print(\"train %d/%d epochs Batch %d Loss:%f, Acc:%f\" %(epoch+1,epochs, (i+1), train_loss/(i+1),train_acc/(i+1)))\n",
    "    print(\"train %d/%d epochs Loss:%f, Acc:%f\" %(epoch+1,epochs,train_loss/(i+1),train_acc/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8675    0.9290       249\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.8675       249\n",
      "   macro avg     0.5000    0.4337    0.4645       249\n",
      "weighted avg     1.0000    0.8675    0.9290       249\n",
      "\n",
      "[[216  33]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\download\\sd\\sd-webui-aki-v4.5\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\download\\sd\\sd-webui-aki-v4.5\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\download\\sd\\sd-webui-aki-v4.5\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#6、evaluate\n",
    "\n",
    "print(\"evaluate...\")\n",
    "pred_list = []\n",
    "y_list = []\n",
    "mymodel.eval()\n",
    "for j,batch in enumerate(val_loader):\n",
    "    val_input_ids,val_attention_mask,val_labels=[elem.to(device) for elem in batch]\n",
    "    with torch.no_grad():\n",
    "        pred=mymodel(val_input_ids,val_attention_mask)\n",
    "        pred=pred.detach().cpu().numpy()\n",
    "        pred_flat=np.argmax(pred,axis=1).flatten()\n",
    "        pred_list.extend(pred_flat)\n",
    "        val_labels=val_labels.detach().cpu().numpy()\n",
    "        y_list.extend(val_labels)\n",
    "\n",
    "classify_report = metrics.classification_report(pred_list, y_list, digits=4) #分类报告 support测试集样本数\n",
    "print(classify_report) \n",
    "confusion_matrix = metrics.confusion_matrix(pred_list, y_list) #混淆矩阵\n",
    "print(confusion_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
