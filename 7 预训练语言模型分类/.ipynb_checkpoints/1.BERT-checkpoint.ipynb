{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言模型，由Google在2018年提出。BERT通过大规模的无监督预训练来学习通用的语言表示，然后在各种NLP任务上进行微调，取得了显著的性能提升。\n",
    "\n",
    "BERT的原理如下：\n",
    "\n",
    "1. **Transformer架构**：BERT使用Transformer编码器作为基础架构，包括多层的自注意力机制和前馈神经网络。这种架构能够更好地捕捉输入序列的全局依赖关系。\n",
    "\n",
    "2. **双向性**：BERT通过两种预训练任务来训练模型，包括Masked Language Model（MLM）和Next Sentence Prediction（NSP）。MLM任务要求模型预测句子中被掩盖的词语，从而使模型能够理解句子的上下文关系；NSP任务要求模型判断两个句子是否是原文中相邻的句子，从而使模型能够理解句子间的逻辑关系。\n",
    "\n",
    "3. **预训练和微调**：BERT首先在大规模文本语料上进行无监督预训练，学习通用的语言表示。然后，在特定的下游任务上进行微调，通过少量标记数据即可取得较好的效果。\n",
    "\n",
    "BERT解决了传统语言模型的一些问题，包括：\n",
    "\n",
    "- **上下文理解**：传统的语言模型（如Word2Vec和GloVe）无法考虑句子中词语的上下文信息，而BERT通过双向性和Transformer架构能够更好地理解句子中的语境，从而提高了语言表示的质量。\n",
    "\n",
    "- **迁移学习**：传统的语言模型通常需要针对特定任务重新训练，而BERT的预训练-微调框架使得模型可以更轻松地应用于各种NLP任务，极大地提高了模型的可迁移性和通用性。\n",
    "\n",
    "BERT有多个版本，其中最知名的是BERT-base和BERT-large。它们的参数规模分别如下：\n",
    "\n",
    "- BERT-base：包含110M个参数，包括12个Transformer编码器层，每层有12个注意力头，隐藏层大小为768。\n",
    "- BERT-large：包含340M个参数，包括24个Transformer编码器层，每层有16个注意力头，隐藏层大小为1024。\n",
    "\n",
    "除此之外，还有一些针对特定任务或语言的变体，如多语言BERT（BERT-multilingual）等。BERT的提出极大地推动了自然语言处理领域的发展，并在许多任务上取得了state-of-the-art的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert模型文件下载地址 https://huggingface.co/bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型对应的tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(r'E:\\code\\bert-base-chinese')\n",
    "# 载入模型\n",
    "model = BertModel.from_pretrained(r'E:\\code\\bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2769, 4263, 1266, 776, 1921, 2128, 7305, 102]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "input_text = \"我爱北京天安门\"\n",
    "# 通过tokenizer把文本变成 token_id\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([input_ids])\n",
    "# 获得BERT模型最后一个隐层结果\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243, 2)\n"
     ]
    }
   ],
   "source": [
    "#1、加载数据\n",
    "train_df = pd.read_csv('data.csv', encoding='utf-8', header=None, names=['label','review'])\n",
    "print(train_df.shape)\n",
    "\n",
    "sentences = list(train_df['review'][1:])\n",
    "label =train_df['label'][1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1120, '1': 122}\n"
     ]
    }
   ],
   "source": [
    "c = Counter(label)\n",
    "print (dict(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 token encodding\n",
    "model_path = r'E:\\code\\bert-base-chinese'\n",
    "tokenizer=BertTokenizer.from_pretrained(model_path)\n",
    "max_length=32\n",
    "sentences_tokened=tokenizer(sentences,padding=True,truncation=True,max_length=max_length, return_tensors='pt')\n",
    "label=torch.tensor(label.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993, 249]\n"
     ]
    }
   ],
   "source": [
    "#3 encoding data\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "\n",
    "class DataToDataset(Dataset):\n",
    "    def __init__(self,encoding,labels):\n",
    "        self.encoding=encoding\n",
    "        self.labels=labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.encoding['input_ids'][index],self.encoding['attention_mask'][index],self.labels[index]\n",
    "\n",
    "#封装数据\n",
    "datasets=DataToDataset(sentences_tokened,label)\n",
    "train_size=int(len(datasets)*0.8)\n",
    "test_size=len(datasets)-train_size\n",
    "print([train_size,test_size])\n",
    "train_dataset,val_dataset=random_split(dataset=datasets,lengths=[train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "#这里的num_workers要大于0\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "val_loader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at E:\\code\\bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTextClassficationModel(\n",
       "  (bert): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4、create model\n",
    "class BertTextClassficationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertTextClassficationModel,self).__init__()\n",
    "        self.bert=BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "        \n",
    "    def forward(self,ids,mask):\n",
    "        out = self.bert(input_ids=ids,attention_mask=mask)\n",
    "        return out[0]\n",
    "\n",
    "\n",
    "mymodel=BertTextClassficationModel()\n",
    "\n",
    "\n",
    "#获取gpu和cpu的设备信息\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(\"Let's use \",torch.cuda.device_count(),\"GPUs!\")\n",
    "    mymodel=nn.DataParallel(mymodel)\n",
    "mymodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.bert.embeddings.word_embeddings.weight : torch.Size([21128, 768])\n",
      "bert.bert.embeddings.position_embeddings.weight : torch.Size([512, 768])\n",
      "bert.bert.embeddings.token_type_embeddings.weight : torch.Size([2, 768])\n",
      "bert.bert.embeddings.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.embeddings.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.0.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.0.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.0.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.0.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.0.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.1.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.1.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.1.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.1.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.1.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.2.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.2.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.2.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.2.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.2.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.3.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.3.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.3.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.3.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.3.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.4.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.4.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.4.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.4.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.4.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.5.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.5.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.5.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.5.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.5.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.6.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.6.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.6.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.6.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.6.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.7.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.7.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.7.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.7.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.7.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.8.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.8.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.8.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.8.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.8.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.9.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.9.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.9.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.9.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.9.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.10.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.10.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.10.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.10.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.10.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.query.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.query.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.key.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.key.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.self.value.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.self.value.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.encoder.layer.11.attention.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.attention.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.intermediate.dense.weight : torch.Size([3072, 768])\n",
      "bert.bert.encoder.layer.11.intermediate.dense.bias : torch.Size([3072])\n",
      "bert.bert.encoder.layer.11.output.dense.weight : torch.Size([768, 3072])\n",
      "bert.bert.encoder.layer.11.output.dense.bias : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.output.LayerNorm.weight : torch.Size([768])\n",
      "bert.bert.encoder.layer.11.output.LayerNorm.bias : torch.Size([768])\n",
      "bert.bert.pooler.dense.weight : torch.Size([768, 768])\n",
      "bert.bert.pooler.dense.bias : torch.Size([768])\n",
      "bert.classifier.weight : torch.Size([2, 768])\n",
      "bert.classifier.bias : torch.Size([2])\n",
      "模型需要训练参数为： 102269186\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for name, parameters in mymodel.named_parameters():\n",
    "    if not parameters.requires_grad: continue\n",
    "    print(name, ':', parameters.size())\n",
    "    total_params += parameters.numel()\n",
    "print(\"模型需要训练参数为：\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1/3 epochs Batch 10 Loss:0.378418, Acc:0.856250\n",
      "train 1/3 epochs Batch 20 Loss:0.281488, Acc:0.884375\n",
      "train 1/3 epochs Batch 30 Loss:0.222678, Acc:0.914583\n",
      "train 1/3 epochs Batch 40 Loss:0.181724, Acc:0.931250\n",
      "train 1/3 epochs Batch 50 Loss:0.158731, Acc:0.942500\n",
      "train 1/3 epochs Batch 60 Loss:0.143904, Acc:0.946875\n",
      "train 1/3 epochs Loss:0.139648, Acc:0.948413\n",
      "train 2/3 epochs Batch 10 Loss:0.054197, Acc:0.993750\n",
      "train 2/3 epochs Batch 20 Loss:0.030179, Acc:0.996875\n",
      "train 2/3 epochs Batch 30 Loss:0.032228, Acc:0.995833\n",
      "train 2/3 epochs Batch 40 Loss:0.079181, Acc:0.981250\n",
      "train 2/3 epochs Batch 50 Loss:0.078001, Acc:0.980000\n",
      "train 2/3 epochs Batch 60 Loss:0.102131, Acc:0.966667\n",
      "train 2/3 epochs Loss:0.106423, Acc:0.966270\n",
      "train 3/3 epochs Batch 10 Loss:0.392596, Acc:0.881250\n",
      "train 3/3 epochs Batch 20 Loss:0.351210, Acc:0.871875\n",
      "train 3/3 epochs Batch 30 Loss:0.271807, Acc:0.906250\n",
      "train 3/3 epochs Batch 40 Loss:0.235043, Acc:0.912500\n",
      "train 3/3 epochs Batch 50 Loss:0.235598, Acc:0.903750\n",
      "train 3/3 epochs Batch 60 Loss:0.223385, Acc:0.910417\n",
      "train 3/3 epochs Loss:0.213139, Acc:0.914683\n"
     ]
    }
   ],
   "source": [
    "#5、train model\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(mymodel.parameters(),lr=0.0001)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def flat_accuracy(preds,labels):\n",
    "    pred_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return accuracy_score(labels_flat,pred_flat)\n",
    "\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc=0.0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        input_ids,attention_mask,labels=[elem.to(device) for elem in data]\n",
    "        #优化器置零\n",
    "        optimizer.zero_grad()\n",
    "        #得到模型的结果\n",
    "        out=mymodel(input_ids.long(),attention_mask)\n",
    "        #计算误差\n",
    "        loss=loss_func(out,labels)\n",
    "        train_loss += loss.item()\n",
    "        #误差反向传播\n",
    "        loss.backward()\n",
    "        #更新模型参数\n",
    "        optimizer.step()\n",
    "        #计算acc \n",
    "        #out=out.detach().numpy()\n",
    "        out=out.detach().cpu().numpy()\n",
    "        #labels=labels.detach().numpy()\n",
    "        labels=labels.detach().cpu().numpy()\n",
    "        train_acc+=flat_accuracy(out,labels)\n",
    "        if (i + 1) % 10 == 0:\n",
    "                print(\"train %d/%d epochs Batch %d Loss:%f, Acc:%f\" %(epoch+1,epochs, (i+1), train_loss/(i+1),train_acc/(i+1)))\n",
    "    print(\"train %d/%d epochs Loss:%f, Acc:%f\" %(epoch+1,epochs,train_loss/(i+1),train_acc/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9731    0.9864    0.9797       220\n",
      "           1     0.8846    0.7931    0.8364        29\n",
      "\n",
      "    accuracy                         0.9639       249\n",
      "   macro avg     0.9289    0.8897    0.9080       249\n",
      "weighted avg     0.9628    0.9639    0.9630       249\n",
      "\n",
      "[[217   3]\n",
      " [  6  23]]\n"
     ]
    }
   ],
   "source": [
    "#6、evaluate\n",
    "\n",
    "print(\"evaluate...\")\n",
    "pred_list = []\n",
    "y_list = []\n",
    "mymodel.eval()\n",
    "for j,batch in enumerate(val_loader):\n",
    "    val_input_ids,val_attention_mask,val_labels=[elem.to(device) for elem in batch]\n",
    "    with torch.no_grad():\n",
    "        pred=mymodel(val_input_ids,val_attention_mask)\n",
    "        pred=pred.detach().cpu().numpy()\n",
    "        pred_flat=np.argmax(pred,axis=1).flatten()\n",
    "        pred_list.extend(pred_flat)\n",
    "        val_labels=val_labels.detach().cpu().numpy()\n",
    "        y_list.extend(val_labels)\n",
    "\n",
    "classify_report = metrics.classification_report(pred_list, y_list, digits=4) #分类报告 support测试集样本数\n",
    "print(classify_report) \n",
    "confusion_matrix = metrics.confusion_matrix(pred_list, y_list) #混淆矩阵\n",
    "print(confusion_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
