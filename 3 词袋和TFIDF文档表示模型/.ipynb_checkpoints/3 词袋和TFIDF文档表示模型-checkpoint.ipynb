{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档表示模型\n",
    "\n",
    "文档表示模型是指将文档表示为向量或者矩阵的模型，用于在自然语言处理任务中表示和处理文本数据。文档表示模型的目标是将文档中的语义信息转化为机器可处理的形式，以便进行文本分类、信息检索、文本相似度计算等任务。\n",
    "\n",
    "常见的文档表示模型包括：\n",
    "\n",
    "词袋模型（Bag of Words，BoW）：将文档表示为一个词语的集合，忽略词语的顺序和语法，只考虑词语的出现频率。每个文档可以表示为一个向量，向量的每个元素表示对应词语的出现次数或者 TF-IDF 值。\n",
    "\n",
    "TF-IDF 模型：TF-IDF 是一种用于衡量词语在文档中重要性的方法，将词频（TF）与逆文档频率（IDF）相乘得到一个词语的权重。文档可以表示为一个 TF-IDF 权重的向量。\n",
    "\n",
    "word2vec 模型：将词语表示为连续的向量，通过学习文本数据中词语的分布式表示，使得语义相近的词在向量空间中距离较近。可以将文档表示为其中包含的词向量的平均值或者加权平均值。\n",
    "\n",
    "BERT 模型：基于 Transformer 架构的预训练模型，可以学习到上下文相关的词语表示。可以通过对整个文档进行编码，得到文档的向量表示。\n",
    "\n",
    "## 词袋文档表示模型\n",
    "\n",
    "词袋模型（Bag of Words，简称BoW）是自然语言处理中常用的一种基本表示文本的方法。它将文本看作是一个袋子，里面装着不考虑顺序的词语，只关注每个词语在文本中出现的频率。词袋模型忽略了词语在文本中的顺序和语法，只关注词语的出现情况，因此被称为\"词袋\"。\n",
    "\n",
    "词袋模型诞生于20世纪50年代末到60年代初，最早被应用于信息检索领域。随着计算机和自然语言处理技术的发展，词袋模型逐渐被引入到文本分类、情感分析等领域，并成为了自然语言处理中的经典方法之一。\n",
    "\n",
    "## TF-IDF文档表示模型\n",
    "\n",
    "TF-IDF（Term Frequency-Inverse Document Frequency，词频-逆文档频率）是一种用于信息检索和文本挖掘的常用加权技术。它将一个词在文档中的重要性表示为这个词在文档中的频率（TF）和逆文档频率（IDF）的乘积。TF表示词在文档中出现的频率，IDF表示词的稀有程度。\n",
    "\n",
    "TF-IDF模型的思想是，如果一个词在一篇文档中出现频率高（TF高），并且在其他文档中很少出现（IDF高），则认为这个词对于这篇文档来说具有很高的重要性。\n",
    "\n",
    "TF-IDF模型最早由Karen Spärck Jones在1972年的一篇论文中提出，并逐渐成为信息检索领域中常用的文本表示方法之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化分词对象\n",
    "vec = CountVectorizer(token_pattern='[\\u4e00-\\u9fa5_a-zA-Z0-9]{1,}') #实例化词袋向量化对象\n",
    "\n",
    "# 将文本进行词袋处理\n",
    "corpus = [\"我 送 你 离开 千里之外\",\n",
    "        \"你 无声 黑白\",\n",
    "        \"你 你 你 离开 天涯之外\",\n",
    "        \"你 是否 还在\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'我': 3, '送': 8, '你': 0, '离开': 6, '千里之外': 1, '无声': 4, '黑白': 9, '天涯之外': 2, '是否': 5, '还在': 7}\n",
      "[[1 1 0 1 0 0 1 0 1 0]\n",
      " [1 0 0 0 1 0 0 0 0 1]\n",
      " [3 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = vec.fit_transform(corpus) #将输入语料转化为字典和词袋向量化表示\n",
    "print(vec.vocabulary_) #输出由数据中所有出现的词构成的词典\n",
    "print(X.toarray()) #词袋向量化表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 1 0 1 0 0 1 0 1 0]表示数据中第一条文本\"我 送 你 离开 千里之外\"中0号词'你'出现了1次， 1号词'千里之外'出现了一次，2号词'天涯之外'出现了0次，3号词'送'出现了1次……依此类推\n",
    "\n",
    "词频（Term Frequency，TF）是指某个词在文本中出现的频率。它通常用于衡量一个词对于某篇文档的重要性。计算词频的公式如下：\n",
    "\n",
    "$\\text{TF}(t, d) = \\frac{n_{t, d}}{n_d}$\n",
    "\n",
    "其中：\n",
    "\n",
    "$t$ 表示某个词（term）。\n",
    "$d$ 表示某篇文档（document）。\n",
    "$n_{t, d}$ 表示词 (t) 在文档 $d$中出现的次数。\n",
    "$n_d$表示文档$d$的总词数。\n",
    "这个公式表示了词$t$在文档$d$中的相对频率。当$n_{t, d}$较大时，词$t$对于文档$d$来说更重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'我': 3, '送': 8, '你': 0, '离开': 6, '千里之外': 1, '无声': 4, '黑白': 9, '天涯之外': 2, '是否': 5, '还在': 7}\n",
      "[1.         1.91629073 1.91629073 1.91629073 1.91629073 1.91629073\n",
      " 1.51082562 1.91629073 1.91629073 1.91629073]\n"
     ]
    }
   ],
   "source": [
    "#TFIDF模型\n",
    "# 建立transform\n",
    "vectorizer = TfidfVectorizer(token_pattern='[\\u4e00-\\u9fa5_a-zA-Z0-9]{1,}')\n",
    "#建立词汇表\n",
    "vectorizer.fit(corpus)\n",
    "# 输出结果\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_) #输出每个词的逆文档频率（IDF）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆文档频率（IDF）是用来衡量一个词语在一个文档集合中的重要性的指标，计算公式如下：\n",
    "\n",
    "$\\text{IDF}(t) = \\log\\left(\\frac{\\text{语料中的文档总数}}{\\text{包含词t的文档数 + 1}}\\right)$\n",
    "\n",
    "\n",
    "IDF 的计算公式是总文档数除以包含该词的文档数的对数。这样做的目的是为了降低常见词的权重，同时增加罕见词的权重，以便更好地区分文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "[[0.26445122 0.50676543 0.         0.50676543 0.         0.\n",
      "  0.39953968 0.         0.50676543 0.        ]\n",
      " [0.34618161 0.         0.         0.         0.66338461 0.\n",
      "  0.         0.         0.         0.66338461]\n",
      " [0.7757673  0.         0.4955319  0.         0.         0.\n",
      "  0.39068304 0.         0.         0.        ]\n",
      " [0.34618161 0.         0.         0.         0.         0.66338461\n",
      "  0.         0.66338461 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 编码文件\n",
    "vector = vectorizer.transform(corpus)\n",
    "# 输出编码结果\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF值为两者的乘积：$\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)$这个值表示词语$t$在文档$d$中的重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  文本  标签\n",
      "0                       商业秘密 秘密性 维系 商业价值 垄断 地位 前提条件    0\n",
      "1  南口 阿玛施 新春 第一批 限量 春装 店 春暖花开 淑女 裙冰 蓝色 公主 衫 气质 粉小...   1\n",
      "2                                 带给 常州 一场 壮观 视觉 盛宴    0\n",
      "3                                     原因 不明 泌尿系统 结石    0\n",
      "4                                    年 盐城 拉回来 麻麻 嫁妆    0\n"
     ]
    }
   ],
   "source": [
    "#读取数据\n",
    "df = pd.read_csv('分词后data.csv')\n",
    "df.dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241 1241\n"
     ]
    }
   ],
   "source": [
    "data = df['文本'].tolist()\n",
    "label = df['标签'].tolist()\n",
    "print(len(data), len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241, 5918)\n"
     ]
    }
   ],
   "source": [
    "#将文本数据转换为tfidf特征矩阵\n",
    "tifidf_model = TfidfVectorizer(token_pattern='[\\u4e00-\\u9fa5_a-zA-Z0-9]{1,}')\n",
    "tfidf_feature = tifidf_model.fit_transform(data)\n",
    "#输出tfidf特征矩阵维度\n",
    "print(tfidf_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1241表示语料数据中文本的数量，5918表示特征维度（字典大小）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
