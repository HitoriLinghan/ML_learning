{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b11ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at E:\\code\\bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM , AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "model_path=r\"E:\\code\\bert-base-chinese\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521cab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243, 2)\n",
      "['商业秘密的秘密性那是维系其商业价值和垄断地位的前提条件之一', '南口阿玛施新春第一批限量春装到店啦\\ue310   \\ue310   \\ue310   春暖花开淑女裙、冰蓝色公主衫\\ue006   气质粉小西装、冰丝女王长半裙、\\ue319   皇', '带给我们大常州一场壮观的视觉盛宴', '有原因不明的泌尿系统结石等', '23年从盐城拉回来的麻麻的嫁妆']\n",
      "[0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#1、加载数据\n",
    "train_df = pd.read_csv(r'data.csv', encoding='utf-8', header=None, names=['label','review'])\n",
    "print(train_df.shape)\n",
    "\n",
    "sentences = list(train_df['review'][1:])\n",
    "labels =train_df['label'][1:].values\n",
    "labels = [int(i) for i in labels]\n",
    "print(sentences[0:5])\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbedf34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1120, 1: 122}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(labels)\n",
    "print (dict(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c0882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221\n",
      "1415\n"
     ]
    }
   ],
   "source": [
    "prompt=\"这是一条垃圾短信吗？答案是[MASK]。\"\n",
    "goodToken=\"是\"\n",
    "badToken=\"否\"\n",
    "good=tokenizer.convert_tokens_to_ids(goodToken)\n",
    "bad=tokenizer.convert_tokens_to_ids(badToken)\n",
    "print(good)\n",
    "print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a97c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=21128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取gpu和cpu的设备信息\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(\"Let's use \",torch.cuda.device_count(),\"GPUs!\")\n",
    "    model=nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a311d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 1118]\n"
     ]
    }
   ],
   "source": [
    "#batch finetune\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "\n",
    "class DataToDataset(Dataset):\n",
    "    def __init__(self,sentences,labels):\n",
    "        self.sentences = [sen + prompt for sen in sentences]\n",
    "        self.tokens_tensor = tokenizer(self.sentences, return_tensors='pt', padding=True)['input_ids']\n",
    "        self.mask_pos = [torch.nonzero(item==103).squeeze() for item in self.tokens_tensor]\n",
    "        self.labels = torch.tensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.tokens_tensor[index],self.mask_pos[index],self.labels[index]\n",
    "\n",
    "#封装数据\n",
    "\n",
    "datasets=DataToDataset(sentences,labels)\n",
    "train_size=int(len(datasets)*0.1) #仅用10%数据的训练\n",
    "test_size=len(datasets)-train_size\n",
    "print([train_size,test_size])\n",
    "train_dataset,val_dataset=random_split(dataset=datasets,lengths=[train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de0f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "#这里的num_workers要大于0\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "val_loader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5aea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1/3 epochs Batch 10 Loss:0.622141, Acc:0.950000\n",
      "train 1/3 epochs Batch 20 Loss:0.419353, Acc:0.950000\n",
      "train 1/3 epochs Batch 30 Loss:0.348910, Acc:0.933333\n",
      "train 1/3 epochs Loss:0.337670, Acc:0.935484\n",
      "train 2/3 epochs Batch 10 Loss:0.102772, Acc:0.950000\n",
      "train 2/3 epochs Batch 20 Loss:0.065760, Acc:0.975000\n",
      "train 2/3 epochs Batch 30 Loss:0.045607, Acc:0.983333\n",
      "train 2/3 epochs Loss:0.044241, Acc:0.983871\n",
      "train 3/3 epochs Batch 10 Loss:0.003213, Acc:1.000000\n",
      "train 3/3 epochs Batch 20 Loss:0.002806, Acc:1.000000\n",
      "train 3/3 epochs Batch 30 Loss:0.002026, Acc:1.000000\n",
      "train 3/3 epochs Loss:0.002212, Acc:1.000000\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "lossFunc=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def flat_accuracy(preds,labels):\n",
    "    pred_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return accuracy_score(labels_flat,pred_flat)\n",
    "\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc=0.0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        tokens_tensor,mask_pos,labels=[elem.to(device) for elem in data]\n",
    "        #优化器置零\n",
    "        optimizer.zero_grad()\n",
    "        #得到模型的结果\n",
    "        outputs = model(tokens_tensor.cuda(device))\n",
    "        predictions = outputs[0]\n",
    "        pred = torch.zeros(len(mask_pos), 2)\n",
    "        for inum in range(len(mask_pos)):\n",
    "            #print(mask_pos[inum])\n",
    "            pred[inum] = predictions[inum, mask_pos[inum]][[bad,good]]\n",
    "        #计算误差\n",
    "        loss=lossFunc(pred.to(device), labels)\n",
    "        train_loss += loss.item()\n",
    "        #误差反向传播\n",
    "        loss.backward()\n",
    "        #更新模型参数\n",
    "        optimizer.step()\n",
    "        #计算acc \n",
    "        #out=pred.detach().numpy()\n",
    "        pred=pred.detach().cpu().numpy()\n",
    "        #labels=labels.detach().numpy()\n",
    "        labels=labels.detach().cpu().numpy()\n",
    "        train_acc+=flat_accuracy(pred,labels)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(\"train %d/%d epochs Batch %d Loss:%f, Acc:%f\" %(epoch+1,epochs, (i+1), train_loss/(i+1),train_acc/(i+1)))\n",
    "    print(\"train %d/%d epochs Loss:%f, Acc:%f\" %(epoch+1,epochs,train_loss/(i+1),train_acc/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c6ae8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    0.9862    0.9897      1018\n",
      "           1     0.8692    0.9300    0.8986       100\n",
      "\n",
      "    accuracy                         0.9812      1118\n",
      "   macro avg     0.9311    0.9581    0.9441      1118\n",
      "weighted avg     0.9820    0.9812    0.9815      1118\n",
      "\n",
      "[[1004   14]\n",
      " [   7   93]]\n"
     ]
    }
   ],
   "source": [
    "#batch evaluate\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"evaluate...\")\n",
    "pred_list = []\n",
    "y_list = []\n",
    "model.eval()\n",
    "for j,batch in enumerate(val_loader):\n",
    "    tokens_tensor,mask_pos,val_labels=[elem.to(device) for elem in batch]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor.cuda(device))\n",
    "        predictions = outputs[0]\n",
    "        pred = torch.zeros(len(mask_pos), 2)\n",
    "        for inum in range(len(mask_pos)):\n",
    "            pred[inum] = predictions[inum, mask_pos[inum]][[bad,good]]\n",
    "        pred=pred.detach().cpu().numpy()\n",
    "        pred_flat=np.argmax(pred,axis=1).flatten()\n",
    "        pred_list.extend(pred_flat)\n",
    "        val_labels=val_labels.detach().cpu().numpy()\n",
    "        y_list.extend(val_labels)\n",
    "    \n",
    "classify_report = metrics.classification_report(pred_list, y_list, digits = 4) #分类报告 support测试集样本数\n",
    "print(classify_report) \n",
    "confusion_matrix = metrics.confusion_matrix(pred_list, y_list) #混淆矩阵\n",
    "print(confusion_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e50e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956689e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
